{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[209, 1336, 1377, 2607, 2648, 3562, 3631, 4164, 4205]\n",
      "[106]\n",
      "[81]\n",
      "[86]\n",
      "[103, 931, 968, 1347, 1377]\n",
      "[81]\n",
      "[34]\n",
      "[94, 1487, 1528, 1635, 1683, 2212, 2253]\n",
      "[1667]\n",
      "[]\n",
      "[]\n",
      "[126]\n",
      "[81]\n",
      "[73]\n",
      "[95, 465, 644, 685, 893, 1041, 1082, 1458, 1499, 1687]\n",
      "[]\n",
      "[]\n",
      "[80, 1515, 1552]\n",
      "[40]\n",
      "[75, 441, 486]\n",
      "[34]\n",
      "[]\n",
      "[81]\n",
      "[41]\n",
      "[84]\n",
      "[34]\n",
      "[582]\n",
      "[]\n",
      "[104, 3699]\n",
      "[87]\n",
      "[191, 796]\n",
      "[132]\n",
      "[122]\n",
      "[50]\n",
      "[39, 341]\n",
      "[114, 1448, 1496, 2443]\n",
      "[102, 255, 299]\n",
      "[115, 835, 871, 919, 1412, 1476, 2331]\n",
      "[41]\n",
      "[1929]\n",
      "[]\n",
      "[82, 1759, 1803]\n",
      "[34]\n",
      "[34]\n",
      "[65]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[105, 1876, 1917, 2884, 2933]\n",
      "[34, 178]\n",
      "[75]\n",
      "[122]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[70, 1067, 1139, 1935, 1977, 2359, 2399]\n",
      "[41]\n",
      "[62, 3201, 4327, 4372]\n",
      "[81, 355, 402, 2516, 3065, 3356, 3455, 4111, 4151, 5927, 7053, 7098, 8444, 8792, 8846, 9192, 9244, 10153, 10721, 10882, 11224, 12145, 12188, 14695, 14740, 16505, 16550, 17292, 17458, 18699, 19215, 21138, 23825, 25353]\n",
      "[2954, 5370, 9787, 13915, 14599, 14639, 15208, 15248, 15966, 16014, 16770, 17558, 18580, 22715, 23289, 25899, 26389, 26770, 28720, 29504, 31336, 31691, 32200, 34298, 37039, 37889, 40389, 41614, 47462, 48739, 51606, 51731]\n"
     ]
    }
   ],
   "source": [
    "conjunto_dados = pd.DataFrame()\n",
    "\n",
    "speech_by_speaker = {}\n",
    "\n",
    "files_checked = 0\n",
    "\n",
    "# for file in os.scandir(\"./discursos\"):\n",
    "for file in os.scandir(\"./discursos\"):\n",
    "    files_checked += 1\n",
    "    if (files_checked > 1):\n",
    "        continue\n",
    "    with open(file) as fp:\n",
    "        content = fp.read()\n",
    "\n",
    "        #1) remover datas espalhadas, páginas e afins espalhadas pelos documentos (por causa da coversao PDF para TXT)\n",
    "\n",
    "        datas_texto = re.compile(\"\\d{1,2} \\w+ \\w+ \\w+ \\d{4}\")\n",
    "        datas_texto.sub(\" \", content)\n",
    "\n",
    "        series_numeros = re.compile(\"[A-Z]+ SÉRIE \\W NÚMERO \\d+\")\n",
    "        series_numeros.sub(\" \", content)\n",
    "\n",
    "        #2) criar dicionario de intervencoes para criar dataframe\n",
    "\n",
    "        #2.1) identificar os intervenientes e intervencoes correspondentes\n",
    "\n",
    "        speaker_regex = re.compile(r'^[A|O] Sr\\.ª?( [\\w\\-]+)+([\\-]\\w+)?( \\(\\w+\\))*(?=:)', flags=re.M) \n",
    "        deputadxs = speaker_regex.finditer(content) \n",
    "        deputadxs = [match.group() for match in deputadxs]\n",
    "\n",
    "        # print(deputadxs)\n",
    "\n",
    "        content_on_one_line = ''.join(content.splitlines())\n",
    "\n",
    "        deputadxs = [deputadxs[0]]\n",
    "\n",
    "        for speaker in deputadxs:\n",
    "            content_split_by_speaker = content_on_one_line.split(speaker + ':')\n",
    "            # Get rid of everything before they speak\n",
    "            content_split_by_speaker.pop(0)\n",
    "\n",
    "            # what_they_say = [speech for speech in speaker_regex]\n",
    "            # for each line in content_split_by_speaker\n",
    "            # use the speaker regex to find the next speaker and get everything before that\n",
    "            for line in content_split_by_speaker:\n",
    "                regex = re.compile(r'[A|O] Sr\\.ª?( [\\w\\-]+)+([\\-]\\w+)?( \\(\\w+\\))*(?=:)')\n",
    "                start_of_next_speaker = regex.finditer(line)\n",
    "                print([match.start() for match in start_of_next_speaker])\n",
    "                # either an index or None\n",
    "                next_speaker_index = [match.start() for match in start_of_next_speaker][0]\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "        '''''\n",
    "        conjunto_raw = pd.DataFrame()\n",
    "\n",
    "        conjunto_raw['filename'] = os.path.basename(file)\n",
    "        conjunto_raw[\"dia\"] = dia\n",
    "        conjunto_raw[\"ano\"] = ano\n",
    "\n",
    "        print(conjunto_raw)\n",
    "\n",
    "\n",
    "        conjunto_dados = pd.concat([conjunto_dados, conjunto_raw])'''''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e152dfdee28af8a479f12678d905829ccdbbe8fcec57885e1fc64b78cf4fda49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
